# **IBM Granite 3.1 8B Lab**

## **Model Description**

LAB: Large-scale Alignment for chatBots is a novel synthetic data-based alignment tuning method for LLMs from IBM Research. Granite-8b-lab-v1 is a Granite-8b-base derivative model trained with the LAB methodology, using Mixtral-8x7b-Instruct as a teacher model.


    - Model Name: Granite-8b-lab-v1
    - Language(s): Primarily English
    - License: Apache 2.0
    - Base model: [ibm-granite/granite-3.0-8b-base](https://huggingface.co/ibm-granite/granite-3.0-8b-base)
    - Teacher Model: [mistralai/Mixtral-8x7B-Instruct-v0.1](https://huggingface.co/mistralai/Mixtral-8x7B-Instruct-v0.1)


### **Developed By**
IBM Research

### **GitHub Repository**
[ibm-granite/granite-code-models](https://github.com/ibm-granite/granite-code-models)

### **Model Location**
`oci://registry.redhat.io/rhelai1/modelcar-granite-3-1-8b-lab-v1:1.4.0`

### **Relevant Papers**
[Granite Code Models: A Family of Open Foundation Models for Code Intelligence](https://arxiv.org/abs/2405.04324)

### **Release Date**
February 10, 2025

### **Licensing**
[Apache 2.0](https://www.apache.org/licenses/LICENSE-2.0)

## **Intended Use**
<!--
Sourced from: https://huggingface.co/ibm-granite/granite-8b-code-instruct-4k#intended-use
-->
The model is designed to respond to coding related instructions and can be used to build coding assistants.